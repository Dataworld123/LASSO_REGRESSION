{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edbfde7-f40e-4b9e-85e4-1ae6143e8986",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1113900-37cf-49f8-8dcc-1be8bf5ecde1",
   "metadata": {},
   "source": [
    "Lasso Regression, also known as L1 regularization, is a linear regression technique used for feature selection and regularization. It is particularly useful when dealing with datasets with a large number of features, as it helps prevent overfitting and improves the model's generalization performance.\n",
    "\n",
    "The key characteristic of Lasso Regression is that it adds a penalty term to the linear regression objective function, which is the sum of squared differences between the predicted and actual values (the least squares term). The penalty term is proportional to the absolute values of the coefficients of the features. The objective function of Lasso Regression is given by:\n",
    "\n",
    "Objective Function\n",
    "=\n",
    "Least Squares Term\n",
    "+\n",
    "�\n",
    "×\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "∣\n",
    "�\n",
    "�\n",
    "∣\n",
    "Objective Function=Least Squares Term+λ×∑ \n",
    "i=1\n",
    "n\n",
    "​\n",
    " ∣β \n",
    "i\n",
    "​\n",
    " ∣\n",
    "\n",
    "Here:\n",
    "\n",
    "�\n",
    "�\n",
    "β \n",
    "i\n",
    "​\n",
    "  represents the coefficients of the features.\n",
    "�\n",
    "n is the number of features.\n",
    "�\n",
    "λ is the regularization parameter, controlling the strength of the penalty term.\n",
    "The L1 regularization term (\n",
    "�\n",
    "×\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "∣\n",
    "�\n",
    "�\n",
    "∣\n",
    "λ×∑ \n",
    "i=1\n",
    "n\n",
    "​\n",
    " ∣β \n",
    "i\n",
    "​\n",
    " ∣) encourages sparsity in the model by shrinking some of the coefficients to exactly zero. As a result, Lasso Regression performs automatic feature selection, effectively excluding irrelevant or less important features from the model.\n",
    "\n",
    "Differences from other regression techniques:\n",
    "\n",
    "Ridge Regression (L2 Regularization): Ridge Regression also adds a penalty term to the linear regression objective function, but the penalty term is proportional to the squared values of the coefficients. Unlike Lasso, Ridge does not lead to exact zero coefficients, and it tends to shrink the coefficients towards zero rather than setting them exactly to zero.\n",
    "\n",
    "Elastic Net Regression: Elastic Net combines both L1 and L2 regularization terms in the objective function, allowing for a balance between feature selection (as in Lasso) and coefficient shrinkage (as in Ridge). It includes two parameters, \n",
    "�\n",
    "α and \n",
    "�\n",
    "λ, to control the mix between the L1 and L2 regularization.\n",
    "\n",
    "In summary, Lasso Regression is a linear regression technique that adds an L1 regularization term to the objective function, promoting sparsity in the model and performing automatic feature selection.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404fb0f6-322d-4a5e-a572-5267c6302b8b",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad4e81-24a1-407a-a023-ad8b54e28a31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf23fcb3-78ea-48e6-989e-0e3e0e8d1a55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a67f28-1cdc-4ddf-bcf3-25426545bc97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bab2cd50-222b-4130-bb5f-87c9dbcb2210",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ffebb01-3ed6-43dc-992a-4c344498f1f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9377ec58-9782-493c-a880-f91fe765c123",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de3cc2d-9852-44a2-b2f8-bc13db8d187b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97209637-e4af-4b88-9edf-0e7b9f677ac5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "942a1807-ef44-4e1a-a8a4-a19da426cd1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "052d0d77-8b51-46b5-8dad-a0341ae25de3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a03efc8-1dda-477f-8b6b-38f573851209",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab726b2-9495-48eb-a48b-dc54fb66adb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac353119-fe4d-440b-b640-2f84abcbe159",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
